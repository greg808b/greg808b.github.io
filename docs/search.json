[
  {
    "objectID": "posts/post_5/index.html",
    "href": "posts/post_5/index.html",
    "title": "Anomaly and Outlier Detection",
    "section": "",
    "text": "-DBSCAN labels for scatter plot -Clustering can be used for topic"
  },
  {
    "objectID": "posts/post_3/index.html",
    "href": "posts/post_3/index.html",
    "title": "Linear and Non-Linear Regression",
    "section": "",
    "text": "-Line on scatter plot -Linear : Ridge/Lasso -NonLinear : Random Forest\nWritten currently is titanic example with pipelines\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\n\nX_train = preprocess_pipeline.fit_transform(train_data)\ny_train = train_data[\"Survived\"]\nforest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\nforest_clf.fit(X_train, y_train)\nX_test = preprocess_pipeline.transform(test_data)\ny_pred = forest_clf.predict(X_test)\nforest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\nforest_scores.mean()\n\nfrom sklearn.svm import SVC\n\nsvm_clf = SVC(gamma=\"auto\")\nsvm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\nsvm_scores.mean()\n\n\nplt.figure(figsize=(8, 4))\nplt.plot([1]*10, svm_scores, \".\")\nplt.plot([2]*10, forest_scores, \".\")\nplt.boxplot([svm_scores, forest_scores], labels=(\"SVM\", \"Random Forest\"))\nplt.ylabel(\"Accuracy\")\nplt.show()\n\nC:\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn("
  },
  {
    "objectID": "posts/post_1/index.html",
    "href": "posts/post_1/index.html",
    "title": "Probabiltiy Theory and Random Variables",
    "section": "",
    "text": "-Histogram"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Greg Brinson’s Blog",
    "section": "",
    "text": "Probabiltiy Theory and Random Variables\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2023\n\n\nGreg Brinson\n\n\n\n\n\n\n  \n\n\n\n\nClustering\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2023\n\n\nGreg Brinson\n\n\n\n\n\n\n  \n\n\n\n\nLinear and Non-Linear Regression\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2023\n\n\nGreg Brinson\n\n\n\n\n\n\n  \n\n\n\n\nClassification\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2023\n\n\nGreg Brinson\n\n\n\n\n\n\n  \n\n\n\n\nAnomaly and Outlier Detection\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2023\n\n\nGreg Brinson\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post_2/index.html",
    "href": "posts/post_2/index.html",
    "title": "Clustering",
    "section": "",
    "text": "here we go this is good\n-DBSCAN labels for scatter plot"
  },
  {
    "objectID": "posts/post_4/index.html",
    "href": "posts/post_4/index.html",
    "title": "Classification",
    "section": "",
    "text": "This blog shows the relationship between precision and recall in a Machine Learning context.\n-ROC, PR, Confusion Matrix\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=10000,\n    random_state=42,\n)\ny_train_5 = y_train == '5'  # True for all 5s, False for all other digits\ny_test_5 = y_test == '5'\n\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import SGDClassifier\n\nsgd_clf = SGDClassifier(random_state=42)\nsgd_clf.fit(X_train, y_train_5)\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\ncm = confusion_matrix(y_train_5, y_train_pred)\ncmd = ConfusionMatrixDisplay(cm)\ncmd.plot();\n\n\n\n\nHere you can see the numerical representation of the True Positives and True Negatives.\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import PrecisionRecallDisplay, PredictionErrorDisplay\nfrom sklearn.metrics import precision_recall_curve\n\n\nsgd_clf = SGDClassifier(random_state=42)\nsgd_clf.fit(X_train, y_train_5)\ny_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\nprecisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\nPrecisionRecallDisplay(precisions, recalls).plot();\n\n\n\n\n\nfrom pathlib import Path\n\nIMAGES_PATH = Path() / \"images\" / \"classification\"\nIMAGES_PATH.mkdir(parents=True, exist_ok=True)\n\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)\n\n\nidx_for_90_precision = (precisions &gt;= 0.90).argmax()\nthreshold_for_90_precision = thresholds[idx_for_90_precision]\n\n\nfrom sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches  # extra code – for the curved arrow\n\nfpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n\n\nidx_for_threshold_at_90 = (thresholds &lt;= threshold_for_90_precision).argmax()\ntpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]\n\nplt.figure(figsize=(6, 5))  # extra code – not needed, just formatting\nplt.plot(fpr, tpr, linewidth=2, label=\"ROC curve\")\nplt.plot([0, 1], [0, 1], 'k:', label=\"Random classifier's ROC curve\")\nplt.plot([fpr_90], [tpr_90], \"ko\", label=\"Threshold for 90% precision\")\n\n# extra code – just beautifies and saves Figure 3–7\nplt.gca().add_patch(patches.FancyArrowPatch(\n    (0.20, 0.89), (0.07, 0.70),\n    connectionstyle=\"arc3,rad=.4\",\n    arrowstyle=\"Simple, tail_width=1.5, head_width=8, head_length=10\",\n    color=\"#444444\"))\nplt.text(0.12, 0.71, \"Higher\\nThreshold\", color=\"#333333\")\nplt.xlabel('False Positive Rate (Fall-Out, FPR)')\nplt.ylabel('True Positive Rate (Recall)')\nplt.grid()\nplt.axis([0, 1, 0, 1])\nplt.legend(loc=\"lower right\", fontsize=13)\nsave_fig(\"roc_curve_plot\")\n\nplt.show()"
  }
]